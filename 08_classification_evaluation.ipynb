{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21491b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-06 16:57:44.663275: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-06 16:57:44.952464: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-06 16:57:50.751951: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-11-06 16:57:50.752057: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-11-06 16:57:50.752065: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/jack155861/.local/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.6) or chardet (5.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import pickle, os\n",
    "import numpy as np\n",
    "import pickle, joblib\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model, get_custom_objects\n",
    "from tensorflow.keras.optimizers import SGD, Nadam, Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, CSVLogger, Callback\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.backend import sigmoid\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.python.keras import backend as K\n",
    "import gc\n",
    "from PIL import Image\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f3da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_train_history(train_history):\n",
    "    fig=plt.gcf()\n",
    "    fig.set_size_inches(16, 6)\n",
    "    plt.subplot(121)\n",
    "    plt.plot(train_history[0])\n",
    "    plt.plot(train_history[1])\n",
    "    plt.title(\"Train History\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.subplot(122)\n",
    "    plt.plot(train_history[2])\n",
    "    plt.plot(train_history[3])\n",
    "    plt.title(\"Train History\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "def optimizer_f(optimizer):\n",
    "    if optimizer == \"sgd\":\n",
    "        return SGD(learning_rate=0.001, momentum=0.9, decay=0, nesterov=True)\n",
    "    if optimizer == \"nadam\":\n",
    "        return Nadam(learning_rate=0.001)\n",
    "    if optimizer == 'adam':\n",
    "        return Adam(learning_rate=0.001)\n",
    "#def swish(x, beta = 1):\n",
    "#    return (x * sigmoid(beta * x))\n",
    "#get_custom_objects().update({'swish': swish})\n",
    "def transforms(p=0.75):\n",
    "    return A.Compose([\n",
    "        A.RandomToneCurve(scale=0.3, p=1),\n",
    "        #A.CLAHE(p=0.5),\n",
    "        #A.ColorJitter(brightness=1,contrast=0, saturation=0, hue=0),\n",
    "        #A.RandomBrightnessContrast(),\n",
    "        A.RandomGamma(p=1),\n",
    "        A.Blur(blur_limit=3, p=1)\n",
    "    ], p=p)\n",
    "def augmentor(image):\n",
    "    aug = transforms()\n",
    "    aug_img = aug(image = np.array(image).astype('uint8'))['image']\n",
    "    aug_img = preprocess_input(aug_img)\n",
    "    return aug_img\n",
    "def callbacks_list_fn(file, loss, save_weights_only_, earlystop = True):\n",
    "    if loss==\"sparse\":\n",
    "        monitor_acc = 'val_sparse_categorical_accuracy'\n",
    "    else:\n",
    "        monitor_acc = 'val_accuracy'\n",
    "        \n",
    "    lrate = ReduceLROnPlateau(monitor = monitor_acc, factor=0.75, patience=10, mode='max', min_delta=0.00001, \n",
    "                              cooldown=0, threshold_mode='rel', min_lr=1e-8)    \n",
    "    ck_callback_acc = ModelCheckpoint(file+'/weights_acc.h5', monitor=monitor_acc, mode='max', \n",
    "                                       save_best_only=True, save_weights_only=save_weights_only_)\n",
    "    ck_callback_los = ModelCheckpoint(file+'/weights_loss.h5', monitor='val_loss', mode='min', \n",
    "                                      save_best_only=True, save_weights_only=save_weights_only_)\n",
    "    csv_callback = CSVLogger(file+'/log.csv', append=True, separator=',')\n",
    "    \n",
    "    if earlystop:\n",
    "        earlyst = EarlyStopping(monitor=\"val_loss\", patience = 40, mode='min', min_delta=0.00001)    \n",
    "        return [ck_callback_acc, ck_callback_los, csv_callback, lrate, earlyst]\n",
    "    else:\n",
    "        return [ck_callback_acc, ck_callback_los, csv_callback, lrate]\n",
    "def model_build(activation_, normal_, l2_, optimizer_, pooling_, image_type, loss_):\n",
    "    # 預先訓練好的模型 -- Xception_dataset, 不含後三層(辨識層)\n",
    "    # base_model = ResNet50(weights='imagenet',include_top=False,input_shape=(224, 224, 3))\n",
    "    # base_model = MobileNetV2(weights='imagenet',include_top=False,input_shape=(224, 224, 3))\n",
    "    # base_model.trainable = False\n",
    "    if image_type=='merge':\n",
    "        base_model = MobileNetV2(weights='imagenet',include_top=False,input_shape=(224, 224, 3))\n",
    "    if image_type=='chanel3':\n",
    "        base_model = MobileNetV2(weights='imagenet',include_top=False,input_shape=(224, 224, 3))\n",
    "    if image_type=='chanel3_127':\n",
    "        base_model = MobileNetV2(weights='imagenet',include_top=False,input_shape=(224, 224, 3))\n",
    "    if image_type=='chanel6':\n",
    "        base_model = MobileNetV2(weights=None, include_top=False, input_shape=(224, 224, 6))\n",
    "    if image_type=='chanel12':\n",
    "        base_model = MobileNetV2(weights=None, include_top=False, input_shape=(224, 224, 12))\n",
    "    if image_type=='multi':\n",
    "        base_model_1 = MobileNetV2(weights='imagenet',include_top=False,input_shape=(224, 224, 3))\n",
    "        base_model_2 = MobileNetV2(weights='imagenet',include_top=False,input_shape=(224, 224, 3))\n",
    "        # 連接自訂層\n",
    "        for layer in base_model_1.layers:\n",
    "            layer._name = layer._name + str(\"_1\")\n",
    "        for w in base_model_1.weights:\n",
    "            w._handle_name = w.name + str(\"_1\")\n",
    "        for layer in base_model_2.layers:\n",
    "            layer._name = 'EP_' + layer._name + str(\"_2\")\n",
    "        for w in base_model_2.weights:\n",
    "            w._handle_name = 'EP_' + w.name + str(\"_2\")\n",
    "        base_model = layers.concatenate([base_model_1.output, base_model_2.output])\n",
    "    \n",
    "    if pooling_ == \"max\":\n",
    "        if image_type=='multi':\n",
    "            x = layers.GlobalMaxPooling2D()(base_model)\n",
    "        else:\n",
    "            x = layers.GlobalMaxPooling2D()(base_model.output)\n",
    "    if pooling_ == \"ave\":\n",
    "        if image_type=='multi':\n",
    "            x = layers.GlobalAveragePooling2D()(base_model)\n",
    "        else:\n",
    "            x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    if pooling_ == \"conv\":\n",
    "        if image_type=='multi':\n",
    "            x = layers.Conv2D(1280, (7, 7), activation=\"relu\")(base_model)\n",
    "        else:\n",
    "            x = layers.Conv2D(1280, (7, 7), activation=\"relu\")(base_model.output)\n",
    "    if pooling_ == 'all':\n",
    "        x1 = layers.GlobalMaxPooling2D()(base_model.output)\n",
    "        x2 = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "        x3 = layers.Conv2D(1280, (7, 7), activation=\"relu\")(base_model.output)\n",
    "        x3 = layers.BatchNormalization()(x3)\n",
    "        x3 = layers.Activation(activation_)(x3)\n",
    "        x3 = layers.Flatten()(x3)\n",
    "        x = layers.concatenate([x1, x2, x3])\n",
    "    \n",
    "    if pooling_ == \"conv\":\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(activation_)(x)\n",
    "        x = layers.Flatten()(x)\n",
    "    else:        \n",
    "        if normal_ == 'drop':\n",
    "            x = layers.Dropout(0.25)(x)\n",
    "        if normal_ == 'batch':\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Activation(activation_)(x)\n",
    "        \n",
    "    x = layers.Dense(1024, activation=activation_, kernel_initializer='he_normal', kernel_regularizer=l2(float(l2_)))(x)    \n",
    "    if normal_ == 'drop':\n",
    "        x = layers.Dropout(0.25)(x)\n",
    "    if normal_ == 'batch':\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(activation_)(x)\n",
    "        \n",
    "    x = layers.Dense(256, activation=activation_, kernel_initializer='he_normal', kernel_regularizer=l2(float(l2_)))(x)\n",
    "    if normal_ == 'drop':\n",
    "        x = layers.Dropout(0.25)(x)\n",
    "    if normal_ == 'batch':\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(activation_)(x)\n",
    "        \n",
    "    x = layers.Dense(64, activation=activation_, kernel_initializer='he_normal', kernel_regularizer=l2(float(l2_)))(x)\n",
    "    if normal_ == 'drop':\n",
    "        x = layers.Dropout(0.25)(x)\n",
    "    if normal_ == 'batch':\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(activation_)(x)\n",
    "        \n",
    "    x = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "    # 設定新模型的 inputs/outputs\n",
    "    if image_type=='multi':\n",
    "        model = Model(inputs=[base_model_1.input, base_model_2.input], outputs=x)\n",
    "    else:\n",
    "        model = Model(inputs=base_model.input, outputs=x)\n",
    "    \n",
    "    if loss_==\"sparse\":\n",
    "        model.compile(optimizer = optimizer_f(optimizer_), \n",
    "                      loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])    \n",
    "    else:\n",
    "        model.compile(optimizer = optimizer_f(optimizer_), \n",
    "                      #loss = \"categorical_crossentropy\", \n",
    "                      loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.1),\n",
    "                      metrics=[\"accuracy\"])    \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93eb143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_route = 'chanel3'\n",
    "path_list = [os.path.join(dirpath,filename) for dirpath, _, filenames in os.walk('07_classification_training_' + pkl_route) for filename in filenames if 'weights_final.h5' in filename]\n",
    "with open('06_classification_image/classification_dataset_' + pkl_route + '.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "    \n",
    "train_X_key = [x for x in dataset['training_X'].keys() if x.split(\"_\")[1]=='0']\n",
    "testing_X_key = [x for x in dataset['testing_X'].keys() if x.split(\"_\")[1]=='0']\n",
    "\n",
    "train_X = [dataset['training_X'][x]['image'] for x in train_X_key]\n",
    "train_X = preprocess_input(np.array(train_X))\n",
    "test_X = [dataset['testing_X'][x]['image'] for x in testing_X_key]\n",
    "test_X = preprocess_input(np.array(test_X))\n",
    "train_Y = pd.DataFrame(dataset['training_Y'])\n",
    "train_Y['key'] = dataset['training_X'].keys()\n",
    "train_Y = np.array(train_Y[train_Y['key'].str.contains(\"_0\")][[0,1,2,3,4,5]])\n",
    "test_Y = pd.DataFrame(dataset['testing_Y'])\n",
    "test_Y['key'] = dataset['testing_X'].keys()\n",
    "test_Y = np.array(test_Y[test_Y['key'].str.contains(\"_0\")][[0,1,2,3,4,5]])\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a9481b8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07_classification_training_chanel3/sgd/max/gelu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 171ms/step\n",
      "07_classification_training_chanel3/sgd/max/gelu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 168ms/step\n",
      "07_classification_training_chanel3/sgd/max/gelu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 172ms/step\n",
      "07_classification_training_chanel3/sgd/max/gelu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 19ms/step\n",
      "7/7 [==============================] - 1s 214ms/step\n",
      "07_classification_training_chanel3/sgd/max/gelu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 160ms/step\n",
      "07_classification_training_chanel3/sgd/max/gelu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 158ms/step\n",
      "07_classification_training_chanel3/sgd/max/relu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 217ms/step\n",
      "07_classification_training_chanel3/sgd/max/relu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 157ms/step\n",
      "07_classification_training_chanel3/sgd/max/relu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 155ms/step\n",
      "07_classification_training_chanel3/sgd/max/swish_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 19ms/step\n",
      "7/7 [==============================] - 1s 211ms/step\n",
      "07_classification_training_chanel3/sgd/max/swish_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 156ms/step\n",
      "07_classification_training_chanel3/sgd/max/swish_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 159ms/step\n",
      "07_classification_training_chanel3/sgd/max/tanh_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 232ms/step\n",
      "07_classification_training_chanel3/sgd/max/tanh_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 155ms/step\n",
      "07_classification_training_chanel3/sgd/max/tanh_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 172ms/step\n",
      "07_classification_training_chanel3/sgd/max/swish_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 223ms/step\n",
      "07_classification_training_chanel3/sgd/max/swish_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 181ms/step\n",
      "07_classification_training_chanel3/sgd/max/swish_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 168ms/step\n",
      "07_classification_training_chanel3/sgd/max/relu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 218ms/step\n",
      "07_classification_training_chanel3/sgd/max/relu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 163ms/step\n",
      "07_classification_training_chanel3/sgd/max/relu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 190ms/step\n",
      "07_classification_training_chanel3/sgd/max/tanh_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 243ms/step\n",
      "07_classification_training_chanel3/sgd/max/tanh_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 166ms/step\n",
      "07_classification_training_chanel3/sgd/max/tanh_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 185ms/step\n",
      "07_classification_training_chanel3/sgd/conv/gelu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 4s 23ms/step\n",
      "7/7 [==============================] - 2s 255ms/step\n",
      "07_classification_training_chanel3/sgd/conv/gelu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 176ms/step\n",
      "07_classification_training_chanel3/sgd/conv/gelu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 21ms/step\n",
      "7/7 [==============================] - 1s 174ms/step\n",
      "07_classification_training_chanel3/sgd/conv/gelu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 222ms/step\n",
      "07_classification_training_chanel3/sgd/conv/gelu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 165ms/step\n",
      "07_classification_training_chanel3/sgd/conv/gelu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 166ms/step\n",
      "07_classification_training_chanel3/sgd/conv/relu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 22ms/step\n",
      "7/7 [==============================] - 1s 216ms/step\n",
      "07_classification_training_chanel3/sgd/conv/relu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 161ms/step\n",
      "07_classification_training_chanel3/sgd/conv/relu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 160ms/step\n",
      "07_classification_training_chanel3/sgd/conv/swish_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 214ms/step\n",
      "07_classification_training_chanel3/sgd/conv/swish_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 160ms/step\n",
      "07_classification_training_chanel3/sgd/conv/swish_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 164ms/step\n",
      "07_classification_training_chanel3/sgd/conv/tanh_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 239ms/step\n",
      "07_classification_training_chanel3/sgd/conv/tanh_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 182ms/step\n",
      "07_classification_training_chanel3/sgd/conv/tanh_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 161ms/step\n",
      "07_classification_training_chanel3/sgd/conv/swish_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 222ms/step\n",
      "07_classification_training_chanel3/sgd/conv/swish_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 168ms/step\n",
      "07_classification_training_chanel3/sgd/conv/swish_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/sgd/conv/relu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 220ms/step\n",
      "07_classification_training_chanel3/sgd/conv/relu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 170ms/step\n",
      "07_classification_training_chanel3/sgd/conv/relu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 197ms/step\n",
      "07_classification_training_chanel3/sgd/conv/tanh_batch_0.1/weights_acc.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 233ms/step\n",
      "07_classification_training_chanel3/sgd/conv/tanh_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 21ms/step\n",
      "7/7 [==============================] - 1s 176ms/step\n",
      "07_classification_training_chanel3/sgd/conv/tanh_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 21ms/step\n",
      "7/7 [==============================] - 1s 171ms/step\n",
      "07_classification_training_chanel3/sgd/ave/gelu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 224ms/step\n",
      "07_classification_training_chanel3/sgd/ave/gelu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 171ms/step\n",
      "07_classification_training_chanel3/sgd/ave/gelu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 169ms/step\n",
      "07_classification_training_chanel3/sgd/ave/gelu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 210ms/step\n",
      "07_classification_training_chanel3/sgd/ave/gelu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 160ms/step\n",
      "07_classification_training_chanel3/sgd/ave/gelu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 158ms/step\n",
      "07_classification_training_chanel3/sgd/ave/relu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 224ms/step\n",
      "07_classification_training_chanel3/sgd/ave/relu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 158ms/step\n",
      "07_classification_training_chanel3/sgd/ave/relu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 153ms/step\n",
      "07_classification_training_chanel3/sgd/ave/swish_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 208ms/step\n",
      "07_classification_training_chanel3/sgd/ave/swish_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 173ms/step\n",
      "07_classification_training_chanel3/sgd/ave/swish_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 155ms/step\n",
      "07_classification_training_chanel3/sgd/ave/tanh_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 211ms/step\n",
      "07_classification_training_chanel3/sgd/ave/tanh_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 157ms/step\n",
      "07_classification_training_chanel3/sgd/ave/tanh_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 156ms/step\n",
      "07_classification_training_chanel3/sgd/ave/swish_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 217ms/step\n",
      "07_classification_training_chanel3/sgd/ave/swish_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 164ms/step\n",
      "07_classification_training_chanel3/sgd/ave/swish_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 162ms/step\n",
      "07_classification_training_chanel3/sgd/ave/relu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 19ms/step\n",
      "7/7 [==============================] - 1s 238ms/step\n",
      "07_classification_training_chanel3/sgd/ave/relu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 184ms/step\n",
      "07_classification_training_chanel3/sgd/ave/relu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/sgd/ave/tanh_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 19ms/step\n",
      "7/7 [==============================] - 1s 226ms/step\n",
      "07_classification_training_chanel3/sgd/ave/tanh_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 183ms/step\n",
      "07_classification_training_chanel3/sgd/ave/tanh_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 165ms/step\n",
      "07_classification_training_chanel3/sgd/all/gelu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 4s 22ms/step\n",
      "7/7 [==============================] - 2s 247ms/step\n",
      "07_classification_training_chanel3/sgd/all/gelu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 179ms/step\n",
      "07_classification_training_chanel3/sgd/all/gelu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 181ms/step\n",
      "07_classification_training_chanel3/sgd/all/gelu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 234ms/step\n",
      "07_classification_training_chanel3/sgd/all/gelu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 171ms/step\n",
      "07_classification_training_chanel3/sgd/all/gelu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 169ms/step\n",
      "07_classification_training_chanel3/sgd/all/relu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 219ms/step\n",
      "07_classification_training_chanel3/sgd/all/relu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 164ms/step\n",
      "07_classification_training_chanel3/sgd/all/relu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 164ms/step\n",
      "07_classification_training_chanel3/sgd/all/swish_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 219ms/step\n",
      "07_classification_training_chanel3/sgd/all/swish_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 168ms/step\n",
      "07_classification_training_chanel3/sgd/all/swish_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/sgd/all/tanh_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 227ms/step\n",
      "07_classification_training_chanel3/sgd/all/tanh_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/sgd/all/tanh_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 169ms/step\n",
      "07_classification_training_chanel3/sgd/all/swish_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 235ms/step\n",
      "07_classification_training_chanel3/sgd/all/swish_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 176ms/step\n",
      "07_classification_training_chanel3/sgd/all/swish_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 176ms/step\n",
      "07_classification_training_chanel3/sgd/all/relu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 231ms/step\n",
      "07_classification_training_chanel3/sgd/all/relu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 173ms/step\n",
      "07_classification_training_chanel3/sgd/all/relu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 196ms/step\n",
      "07_classification_training_chanel3/sgd/all/tanh_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 238ms/step\n",
      "07_classification_training_chanel3/sgd/all/tanh_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 179ms/step\n",
      "07_classification_training_chanel3/sgd/all/tanh_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 179ms/step\n",
      "07_classification_training_chanel3/adam/max/gelu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 19ms/step\n",
      "7/7 [==============================] - 1s 173ms/step\n",
      "07_classification_training_chanel3/adam/max/gelu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 170ms/step\n",
      "07_classification_training_chanel3/adam/max/gelu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 192ms/step\n",
      "07_classification_training_chanel3/adam/max/gelu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 157ms/step\n",
      "07_classification_training_chanel3/adam/max/gelu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 157ms/step\n",
      "07_classification_training_chanel3/adam/max/gelu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 158ms/step\n",
      "07_classification_training_chanel3/adam/max/relu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 158ms/step\n",
      "07_classification_training_chanel3/adam/max/relu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 153ms/step\n",
      "07_classification_training_chanel3/adam/max/relu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 156ms/step\n",
      "07_classification_training_chanel3/adam/max/swish_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 154ms/step\n",
      "07_classification_training_chanel3/adam/max/swish_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 170ms/step\n",
      "07_classification_training_chanel3/adam/max/swish_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 158ms/step\n",
      "07_classification_training_chanel3/adam/max/tanh_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 179ms/step\n",
      "07_classification_training_chanel3/adam/max/tanh_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 155ms/step\n",
      "07_classification_training_chanel3/adam/max/tanh_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 156ms/step\n",
      "07_classification_training_chanel3/adam/max/swish_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 19ms/step\n",
      "7/7 [==============================] - 1s 165ms/step\n",
      "07_classification_training_chanel3/adam/max/swish_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 164ms/step\n",
      "07_classification_training_chanel3/adam/max/swish_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 166ms/step\n",
      "07_classification_training_chanel3/adam/max/relu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 166ms/step\n",
      "07_classification_training_chanel3/adam/max/relu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 190ms/step\n",
      "07_classification_training_chanel3/adam/max/relu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 163ms/step\n",
      "07_classification_training_chanel3/adam/max/tanh_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/adam/max/tanh_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 166ms/step\n",
      "07_classification_training_chanel3/adam/max/tanh_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 166ms/step\n",
      "07_classification_training_chanel3/adam/conv/gelu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 174ms/step\n",
      "07_classification_training_chanel3/adam/conv/gelu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 21ms/step\n",
      "7/7 [==============================] - 1s 194ms/step\n",
      "07_classification_training_chanel3/adam/conv/gelu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 173ms/step\n",
      "07_classification_training_chanel3/adam/conv/gelu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 163ms/step\n",
      "07_classification_training_chanel3/adam/conv/gelu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 166ms/step\n",
      "07_classification_training_chanel3/adam/conv/gelu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 165ms/step\n",
      "07_classification_training_chanel3/adam/conv/relu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 161ms/step\n",
      "07_classification_training_chanel3/adam/conv/relu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 161ms/step\n",
      "07_classification_training_chanel3/adam/conv/relu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 186ms/step\n",
      "07_classification_training_chanel3/adam/conv/swish_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 160ms/step\n",
      "07_classification_training_chanel3/adam/conv/swish_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 161ms/step\n",
      "07_classification_training_chanel3/adam/conv/swish_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 184ms/step\n",
      "07_classification_training_chanel3/adam/conv/tanh_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 163ms/step\n",
      "07_classification_training_chanel3/adam/conv/tanh_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 163ms/step\n",
      "07_classification_training_chanel3/adam/conv/tanh_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 162ms/step\n",
      "07_classification_training_chanel3/adam/conv/swish_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 170ms/step\n",
      "07_classification_training_chanel3/adam/conv/swish_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 173ms/step\n",
      "07_classification_training_chanel3/adam/conv/swish_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 172ms/step\n",
      "07_classification_training_chanel3/adam/conv/relu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 168ms/step\n",
      "07_classification_training_chanel3/adam/conv/relu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 21ms/step\n",
      "7/7 [==============================] - 1s 169ms/step\n",
      "07_classification_training_chanel3/adam/conv/relu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 21ms/step\n",
      "7/7 [==============================] - 1s 169ms/step\n",
      "07_classification_training_chanel3/adam/conv/tanh_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/adam/conv/tanh_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 169ms/step\n",
      "07_classification_training_chanel3/adam/conv/tanh_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 170ms/step\n",
      "07_classification_training_chanel3/adam/ave/gelu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 170ms/step\n",
      "07_classification_training_chanel3/adam/ave/gelu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/adam/ave/gelu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 168ms/step\n",
      "07_classification_training_chanel3/adam/ave/gelu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 170ms/step\n",
      "07_classification_training_chanel3/adam/ave/gelu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 159ms/step\n",
      "07_classification_training_chanel3/adam/ave/gelu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 156ms/step\n",
      "07_classification_training_chanel3/adam/ave/relu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 154ms/step\n",
      "07_classification_training_chanel3/adam/ave/relu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 182ms/step\n",
      "07_classification_training_chanel3/adam/ave/relu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 154ms/step\n",
      "07_classification_training_chanel3/adam/ave/swish_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 154ms/step\n",
      "07_classification_training_chanel3/adam/ave/swish_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 154ms/step\n",
      "07_classification_training_chanel3/adam/ave/swish_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 155ms/step\n",
      "07_classification_training_chanel3/adam/ave/tanh_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 156ms/step\n",
      "07_classification_training_chanel3/adam/ave/tanh_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 156ms/step\n",
      "07_classification_training_chanel3/adam/ave/tanh_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 188ms/step\n",
      "07_classification_training_chanel3/adam/ave/swish_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 19ms/step\n",
      "7/7 [==============================] - 1s 166ms/step\n",
      "07_classification_training_chanel3/adam/ave/swish_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 168ms/step\n",
      "07_classification_training_chanel3/adam/ave/swish_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 191ms/step\n",
      "07_classification_training_chanel3/adam/ave/relu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 182ms/step\n",
      "07_classification_training_chanel3/adam/ave/relu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 162ms/step\n",
      "07_classification_training_chanel3/adam/ave/relu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 190ms/step\n",
      "07_classification_training_chanel3/adam/ave/tanh_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 19ms/step\n",
      "7/7 [==============================] - 1s 164ms/step\n",
      "07_classification_training_chanel3/adam/ave/tanh_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 169ms/step\n",
      "07_classification_training_chanel3/adam/ave/tanh_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 165ms/step\n",
      "07_classification_training_chanel3/adam/all/gelu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 185ms/step\n",
      "07_classification_training_chanel3/adam/all/gelu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 185ms/step\n",
      "07_classification_training_chanel3/adam/all/gelu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 198ms/step\n",
      "07_classification_training_chanel3/adam/all/gelu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 169ms/step\n",
      "07_classification_training_chanel3/adam/all/gelu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 189ms/step\n",
      "07_classification_training_chanel3/adam/all/gelu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 171ms/step\n",
      "07_classification_training_chanel3/adam/all/relu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/adam/all/relu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 165ms/step\n",
      "07_classification_training_chanel3/adam/all/relu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 168ms/step\n",
      "07_classification_training_chanel3/adam/all/swish_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 170ms/step\n",
      "07_classification_training_chanel3/adam/all/swish_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 166ms/step\n",
      "07_classification_training_chanel3/adam/all/swish_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 169ms/step\n",
      "07_classification_training_chanel3/adam/all/tanh_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 186ms/step\n",
      "07_classification_training_chanel3/adam/all/tanh_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/adam/all/tanh_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 166ms/step\n",
      "07_classification_training_chanel3/adam/all/swish_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 177ms/step\n",
      "07_classification_training_chanel3/adam/all/swish_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 176ms/step\n",
      "07_classification_training_chanel3/adam/all/swish_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 179ms/step\n",
      "07_classification_training_chanel3/adam/all/relu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 172ms/step\n",
      "07_classification_training_chanel3/adam/all/relu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 176ms/step\n",
      "07_classification_training_chanel3/adam/all/relu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 172ms/step\n",
      "07_classification_training_chanel3/adam/all/tanh_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 176ms/step\n",
      "07_classification_training_chanel3/adam/all/tanh_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 178ms/step\n",
      "07_classification_training_chanel3/adam/all/tanh_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 176ms/step\n",
      "07_classification_training_chanel3/nadam/max/gelu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 169ms/step\n",
      "07_classification_training_chanel3/nadam/max/gelu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 170ms/step\n",
      "07_classification_training_chanel3/nadam/max/gelu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 172ms/step\n",
      "07_classification_training_chanel3/nadam/max/gelu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 159ms/step\n",
      "07_classification_training_chanel3/nadam/max/gelu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 160ms/step\n",
      "07_classification_training_chanel3/nadam/max/gelu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 183ms/step\n",
      "07_classification_training_chanel3/nadam/max/relu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 154ms/step\n",
      "07_classification_training_chanel3/nadam/max/relu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 155ms/step\n",
      "07_classification_training_chanel3/nadam/max/relu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 155ms/step\n",
      "07_classification_training_chanel3/nadam/max/swish_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 155ms/step\n",
      "07_classification_training_chanel3/nadam/max/swish_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 157ms/step\n",
      "07_classification_training_chanel3/nadam/max/swish_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 180ms/step\n",
      "07_classification_training_chanel3/nadam/max/tanh_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 184ms/step\n",
      "07_classification_training_chanel3/nadam/max/tanh_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 156ms/step\n",
      "07_classification_training_chanel3/nadam/max/tanh_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 185ms/step\n",
      "07_classification_training_chanel3/nadam/max/swish_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 164ms/step\n",
      "07_classification_training_chanel3/nadam/max/swish_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 184ms/step\n",
      "07_classification_training_chanel3/nadam/max/swish_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 165ms/step\n",
      "07_classification_training_chanel3/nadam/max/relu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 164ms/step\n",
      "07_classification_training_chanel3/nadam/max/relu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 184ms/step\n",
      "07_classification_training_chanel3/nadam/max/relu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 166ms/step\n",
      "07_classification_training_chanel3/nadam/max/tanh_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 19ms/step\n",
      "7/7 [==============================] - 1s 188ms/step\n",
      "07_classification_training_chanel3/nadam/max/tanh_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 168ms/step\n",
      "07_classification_training_chanel3/nadam/max/tanh_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 165ms/step\n",
      "07_classification_training_chanel3/nadam/conv/gelu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 175ms/step\n",
      "07_classification_training_chanel3/nadam/conv/gelu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 173ms/step\n",
      "07_classification_training_chanel3/nadam/conv/gelu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 196ms/step\n",
      "07_classification_training_chanel3/nadam/conv/gelu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 166ms/step\n",
      "07_classification_training_chanel3/nadam/conv/gelu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 21ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/nadam/conv/gelu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 165ms/step\n",
      "07_classification_training_chanel3/nadam/conv/relu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 182ms/step\n",
      "07_classification_training_chanel3/nadam/conv/relu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 21ms/step\n",
      "7/7 [==============================] - 1s 161ms/step\n",
      "07_classification_training_chanel3/nadam/conv/relu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 162ms/step\n",
      "07_classification_training_chanel3/nadam/conv/swish_drop_0.1/weights_acc.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 181ms/step\n",
      "07_classification_training_chanel3/nadam/conv/swish_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 162ms/step\n",
      "07_classification_training_chanel3/nadam/conv/swish_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 161ms/step\n",
      "07_classification_training_chanel3/nadam/conv/tanh_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 177ms/step\n",
      "07_classification_training_chanel3/nadam/conv/tanh_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 159ms/step\n",
      "07_classification_training_chanel3/nadam/conv/tanh_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 190ms/step\n",
      "07_classification_training_chanel3/nadam/conv/swish_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 169ms/step\n",
      "07_classification_training_chanel3/nadam/conv/swish_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 204ms/step\n",
      "07_classification_training_chanel3/nadam/conv/swish_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 170ms/step\n",
      "07_classification_training_chanel3/nadam/conv/relu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/nadam/conv/relu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 166ms/step\n",
      "07_classification_training_chanel3/nadam/conv/relu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 165ms/step\n",
      "07_classification_training_chanel3/nadam/conv/tanh_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 168ms/step\n",
      "07_classification_training_chanel3/nadam/conv/tanh_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 21ms/step\n",
      "7/7 [==============================] - 1s 169ms/step\n",
      "07_classification_training_chanel3/nadam/conv/tanh_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 168ms/step\n",
      "07_classification_training_chanel3/nadam/ave/gelu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 168ms/step\n",
      "07_classification_training_chanel3/nadam/ave/gelu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 192ms/step\n",
      "07_classification_training_chanel3/nadam/ave/gelu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 19ms/step\n",
      "7/7 [==============================] - 1s 169ms/step\n",
      "07_classification_training_chanel3/nadam/ave/gelu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 155ms/step\n",
      "07_classification_training_chanel3/nadam/ave/gelu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 158ms/step\n",
      "07_classification_training_chanel3/nadam/ave/gelu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 156ms/step\n",
      "07_classification_training_chanel3/nadam/ave/relu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 152ms/step\n",
      "07_classification_training_chanel3/nadam/ave/relu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 152ms/step\n",
      "07_classification_training_chanel3/nadam/ave/relu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 182ms/step\n",
      "07_classification_training_chanel3/nadam/ave/swish_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 156ms/step\n",
      "07_classification_training_chanel3/nadam/ave/swish_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 182ms/step\n",
      "07_classification_training_chanel3/nadam/ave/swish_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 153ms/step\n",
      "07_classification_training_chanel3/nadam/ave/tanh_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 153ms/step\n",
      "07_classification_training_chanel3/nadam/ave/tanh_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 154ms/step\n",
      "07_classification_training_chanel3/nadam/ave/tanh_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 156ms/step\n",
      "07_classification_training_chanel3/nadam/ave/swish_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/nadam/ave/swish_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 180ms/step\n",
      "07_classification_training_chanel3/nadam/ave/swish_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 164ms/step\n",
      "07_classification_training_chanel3/nadam/ave/relu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 163ms/step\n",
      "07_classification_training_chanel3/nadam/ave/relu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 162ms/step\n",
      "07_classification_training_chanel3/nadam/ave/relu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 179ms/step\n",
      "07_classification_training_chanel3/nadam/ave/tanh_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 18ms/step\n",
      "7/7 [==============================] - 1s 163ms/step\n",
      "07_classification_training_chanel3/nadam/ave/tanh_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 164ms/step\n",
      "07_classification_training_chanel3/nadam/ave/tanh_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 18ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/nadam/all/gelu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 198ms/step\n",
      "07_classification_training_chanel3/nadam/all/gelu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 179ms/step\n",
      "07_classification_training_chanel3/nadam/all/gelu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 200ms/step\n",
      "07_classification_training_chanel3/nadam/all/gelu_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/nadam/all/gelu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/nadam/all/gelu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/nadam/all/relu_drop_0.1/weights_acc.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 163ms/step\n",
      "07_classification_training_chanel3/nadam/all/relu_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 164ms/step\n",
      "07_classification_training_chanel3/nadam/all/relu_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 164ms/step\n",
      "07_classification_training_chanel3/nadam/all/swish_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 166ms/step\n",
      "07_classification_training_chanel3/nadam/all/swish_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 165ms/step\n",
      "07_classification_training_chanel3/nadam/all/swish_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 182ms/step\n",
      "07_classification_training_chanel3/nadam/all/tanh_drop_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 167ms/step\n",
      "07_classification_training_chanel3/nadam/all/tanh_drop_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 168ms/step\n",
      "07_classification_training_chanel3/nadam/all/tanh_drop_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 168ms/step\n",
      "07_classification_training_chanel3/nadam/all/swish_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 20ms/step\n",
      "7/7 [==============================] - 1s 188ms/step\n",
      "07_classification_training_chanel3/nadam/all/swish_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 175ms/step\n",
      "07_classification_training_chanel3/nadam/all/swish_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 174ms/step\n",
      "07_classification_training_chanel3/nadam/all/relu_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 171ms/step\n",
      "07_classification_training_chanel3/nadam/all/relu_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 21ms/step\n",
      "7/7 [==============================] - 1s 175ms/step\n",
      "07_classification_training_chanel3/nadam/all/relu_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 173ms/step\n",
      "07_classification_training_chanel3/nadam/all/tanh_batch_0.1/weights_acc.h5\n",
      "60/60 [==============================] - 3s 21ms/step\n",
      "7/7 [==============================] - 1s 176ms/step\n",
      "07_classification_training_chanel3/nadam/all/tanh_batch_0.1/weights_final.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 177ms/step\n",
      "07_classification_training_chanel3/nadam/all/tanh_batch_0.1/weights_loss.h5\n",
      "60/60 [==============================] - 2s 20ms/step\n",
      "7/7 [==============================] - 1s 177ms/step\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "result_groupby = []\n",
    "result_acc = []\n",
    "dic = []\n",
    "for p_ in path_list:\n",
    "    route = '/'.join(p_.split(\"/\")[:-1])\n",
    "    optimizer_ = route.split('/')[1]\n",
    "    pool_ = route.split('/')[2]\n",
    "    activation_, normal_, l2_ = route.split('/')[-1].split(\"_\")\n",
    "    model = model_build(activation_, normal_, l2_, optimizer_, pool_, 'merge', \"sparse\")\n",
    "    \n",
    "    for h5_ in ['weights_acc.h5','weights_final.h5','weights_loss.h5']:    \n",
    "        model_route_tmp = route + \"/\" + h5_\n",
    "        print(model_route_tmp)\n",
    "        model.load_weights(model_route_tmp)\n",
    "        train_X_ = model.predict(train_X)\n",
    "        test_X_ = model.predict(test_X)\n",
    "        train_X_ = pd.concat([pd.DataFrame({'file_name':list(train_X_key),\n",
    "                                            'real_class':np.argmax(train_Y ,axis=1), \n",
    "                                            'predict_class':np.argmax(train_X_ ,axis=1),\n",
    "                                            'dataset':'train'}), \n",
    "                              pd.DataFrame(train_X_)], axis=1)\n",
    "        test_X_ = pd.concat([pd.DataFrame({'file_name':list(testing_X_key),\n",
    "                                           'real_class':np.argmax(test_Y ,axis=1), \n",
    "                                           'predict_class':np.argmax(test_X_ ,axis=1),\n",
    "                                           'dataset':'test'}),\n",
    "                             pd.DataFrame(test_X_)], axis=1)\n",
    "        df = pd.concat([train_X_, test_X_]).reset_index(drop = True)\n",
    "        df['file'] = [x.split(\"_\")[0] for x in df['file_name'].tolist()]\n",
    "\n",
    "        df_groupby = df.groupby(['real_class','predict_class','dataset']).size().rename('num').reset_index(drop = False)\n",
    "        df_groupby = pd.merge(df_groupby[df_groupby['real_class']==df_groupby['predict_class']],\n",
    "                              df.groupby(['real_class','dataset']).size().rename('totla_num').reset_index(drop = False),\n",
    "                              on = ['real_class','dataset'], how = \"left\")\n",
    "        df_groupby['per_num'] = df_groupby['num']/df_groupby['totla_num']\n",
    "        del df_groupby['predict_class']\n",
    "        df_acc = df_groupby \\\n",
    "          .pivot_table(index=['real_class'],columns='dataset',values=['num','totla_num','per_num'],fill_value=0) \\\n",
    "          .reset_index(drop = False)\n",
    "        df_acc.columns = df_acc.columns.map('_'.join).str.strip('_')\n",
    "        \n",
    "        dic_ = {'df_acc_test': sum(df_acc['num_test'])/sum(df_acc['totla_num_test']),\n",
    "                'df_acc_train': sum(df_acc['num_train'])/sum(df_acc['totla_num_train']),\n",
    "                'model_route': model_route_tmp}\n",
    "        dic.append(dic_)\n",
    "\n",
    "        df_groupby['model_route'] = model_route_tmp\n",
    "        df_acc['model_route'] = model_route_tmp\n",
    "        df['model_route'] = model_route_tmp\n",
    "\n",
    "        result.append(df)\n",
    "        result_groupby.append(df_groupby)\n",
    "        result_acc.append(df_acc)\n",
    "        \n",
    "        tf.keras.backend.clear_session() \n",
    "        gc.collect()\n",
    "        \n",
    "    del model\n",
    "\n",
    "result = pd.concat(result).reset_index(drop = True)\n",
    "result_groupby = pd.concat(result_groupby).reset_index(drop = True)\n",
    "result_acc = pd.concat(result_acc).reset_index(drop = True)\n",
    "dic = pd.DataFrame(dic).reset_index(drop = True)\n",
    "\n",
    "result.to_csv('07_classification_training_' + pkl_route + \"/result.csv\", index = False)\n",
    "result_groupby.to_csv('07_classification_training_' + pkl_route + \"/result_groupby.csv\", index = False)\n",
    "result_acc.to_csv('07_classification_training_' + pkl_route + \"/result_acc.csv\", index = False)\n",
    "dic.to_csv('07_classification_training_' + pkl_route + \"/result_all_acc.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90bbfa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['07_classification_training_chanel3/nadam/ave/tanh_drop_0.1/weights_loss.h5']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_class</th>\n",
       "      <th>num_test</th>\n",
       "      <th>num_train</th>\n",
       "      <th>per_num_test</th>\n",
       "      <th>per_num_train</th>\n",
       "      <th>totla_num_test</th>\n",
       "      <th>totla_num_train</th>\n",
       "      <th>model_route</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>173</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>173</td>\n",
       "      <td>07_classification_training_chanel3/nadam/ave/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>309</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.996774</td>\n",
       "      <td>34</td>\n",
       "      <td>310</td>\n",
       "      <td>07_classification_training_chanel3/nadam/ave/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>500</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>56</td>\n",
       "      <td>500</td>\n",
       "      <td>07_classification_training_chanel3/nadam/ave/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>436</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48</td>\n",
       "      <td>436</td>\n",
       "      <td>07_classification_training_chanel3/nadam/ave/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>293</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33</td>\n",
       "      <td>293</td>\n",
       "      <td>07_classification_training_chanel3/nadam/ave/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>194</td>\n",
       "      <td>07_classification_training_chanel3/nadam/ave/t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      real_class  num_test  num_train  per_num_test  per_num_train  \\\n",
       "1523           0        12        173      0.631579       1.000000   \n",
       "1524           1        26        309      0.764706       0.996774   \n",
       "1525           2        52        500      0.928571       1.000000   \n",
       "1526           3        42        436      0.875000       1.000000   \n",
       "1527           4        29        293      0.878788       1.000000   \n",
       "1528           5        20        194      1.000000       1.000000   \n",
       "\n",
       "      totla_num_test  totla_num_train  \\\n",
       "1523              19              173   \n",
       "1524              34              310   \n",
       "1525              56              500   \n",
       "1526              48              436   \n",
       "1527              33              293   \n",
       "1528              20              194   \n",
       "\n",
       "                                            model_route  \n",
       "1523  07_classification_training_chanel3/nadam/ave/t...  \n",
       "1524  07_classification_training_chanel3/nadam/ave/t...  \n",
       "1525  07_classification_training_chanel3/nadam/ave/t...  \n",
       "1526  07_classification_training_chanel3/nadam/ave/t...  \n",
       "1527  07_classification_training_chanel3/nadam/ave/t...  \n",
       "1528  07_classification_training_chanel3/nadam/ave/t...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dic[dic['df_acc_test']>0.86]['model_route'].tolist())\n",
    "url_ = '07_classification_training_chanel3/nadam/ave/tanh_drop_0.1/weights_loss.h5'\n",
    "result_acc[result_acc['model_route']==url_]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
